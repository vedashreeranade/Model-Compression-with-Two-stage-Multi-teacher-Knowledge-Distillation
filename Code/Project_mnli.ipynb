{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a736d316-20aa-4263-84c3-8afc5c4a9cc6",
      "metadata": {
        "id": "a736d316-20aa-4263-84c3-8afc5c4a9cc6",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# SMAI Project - Model Compression with Two-stage Multi-teacher Knowledge Distillation for Web Question Answering System\n",
        "\n",
        "## Group 2 - Synergy\n",
        "\n",
        "| | |\n",
        "|- | -|\n",
        "| Team Members | Roll no |\n",
        "| Anurag Ghosh | `2022202023` |\n",
        "| Aryan Gupta | `2022202028` |\n",
        "| Vedashree Ranade | `2022201073` |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "436f25c4",
      "metadata": {
        "id": "436f25c4",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Step zero: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b37068f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: datasets in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (1.24.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (11.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (2.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (2.28.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from transformers) (2023.3.23)\n",
            "Requirement already satisfied: requests in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/aryangupta/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install datasets\n",
        "!pip3 install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "27212047",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import datasets\n",
        "import transformers\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel, BertConfig\n",
        "import numpy as np"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5e0546f0",
      "metadata": {
        "id": "5e0546f0",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Step one: Loading Datasets\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "bfc9bd68",
      "metadata": {},
      "source": [
        "MNLI Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "da9cc918",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset parquet (/Users/aryangupta/.cache/huggingface/datasets/LysandreJik___parquet/LysandreJik--glue-mnli-train-7ab8f8a28b0cb6f1/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddbb914dc782409181dede38859093f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train size 392702\n",
            "val size 9823\n",
            "test size 9824\n"
          ]
        }
      ],
      "source": [
        "mnli = datasets.load_dataset('LysandreJik/glue-mnli-train')\n",
        "\n",
        "train_dataset = mnli['train']\n",
        "val_test_dataset = mnli['validation']\n",
        "\n",
        "split_size = len(val_test_dataset) // 2\n",
        "val_dataset = val_test_dataset.select(range(0, split_size))\n",
        "test_dataset = val_test_dataset.select(range(split_size, len(val_test_dataset)))\n",
        "\n",
        "print(\"train size\", len(train_dataset))\n",
        "print(\"val size\", len(val_dataset))\n",
        "print(\"test size\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7b82e298",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MNLIDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b25020e7",
      "metadata": {
        "id": "b25020e7",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Step two: Finetuning Teacher Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a49dc9a7",
      "metadata": {
        "id": "a49dc9a7"
      },
      "outputs": [],
      "source": [
        "def get_data(train_dataset, val_dataset, test_dataset, train_size, val_size, test_size, tokenizer):\n",
        "\n",
        "  train_dataset = train_dataset.shuffle()\n",
        "  val_dataset = val_dataset.shuffle()\n",
        "  test_dataset = test_dataset.shuffle()\n",
        "\n",
        "  # select a subset of the shuffled datasets\n",
        "  train_subset = train_dataset.select(range(train_size))\n",
        "  val_subset = val_dataset.select(range(val_size))\n",
        "  test_subset = test_dataset.select(range(test_size)) \n",
        "\n",
        "  # unique, counts = np.unique(test_subset['label'], return_counts=True)\n",
        "  # dict(zip(unique, counts))\n",
        "\n",
        "  train_encodings = tokenizer(train_subset['premise'], train_subset['hypothesis'], truncation=True, padding=True)\n",
        "  val_encodings = tokenizer(val_subset['premise'], val_subset['hypothesis'], truncation=True, padding=True)\n",
        "  test_encodings = tokenizer(test_subset['premise'], test_subset['hypothesis'], truncation=True, padding=True)\n",
        "\n",
        "  train_labels = train_subset['label']\n",
        "  val_labels = val_subset['label']\n",
        "  test_labels = test_subset['label']\n",
        "\n",
        "  train_dataset = MNLIDataset(train_encodings, train_labels)\n",
        "  val_dataset = MNLIDataset(val_encodings, val_labels)\n",
        "  test_dataset = MNLIDataset(test_encodings, test_labels)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=16)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "  return train_loader, val_loader, test_loader, train_labels, val_labels, test_labels, train_subset, val_subset, test_subset\n",
        "\n",
        "def train_model(model, train_loader, optimizer, lr_scheduler):\n",
        "    model.train()\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    \n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        \n",
        "        predictions = outputs.logits.argmax(dim=-1)\n",
        "        correct_predictions += (predictions == labels).sum().item()\n",
        "        total_predictions += predictions.shape[0]\n",
        "        \n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "    # print(\"Training completed...\")\n",
        "    \n",
        "    return correct_predictions / total_predictions\n",
        "    \n",
        "def evaluate_model(loader, model):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    logits = np.empty([0, 3])\n",
        "    i=0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "            labels = batch['labels']\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            batch_logits = outputs.logits.cpu().numpy()\n",
        "            logits = np.concatenate((logits, batch_logits), axis = 0)\n",
        "            predictions = outputs.logits.argmax(dim=-1)\n",
        "            \n",
        "            correct_predictions += (predictions == labels).sum().item()\n",
        "            total_predictions += predictions.shape[0]\n",
        "\n",
        "    return correct_predictions / total_predictions, logits\n",
        "\n",
        "def fine_tune(teacher_model, train_loader, val_loader, test_loader, lr=5e-5, num_epochs=5, checkpoint_dir=None, resume_from_checkpoint=True, checkpoint_file=None):\n",
        "    optimizer = transformers.AdamW(teacher_model.parameters(), lr=lr)\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    lr_scheduler = transformers.get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    checkpoint_path = checkpoint_dir + checkpoint_file\n",
        "\n",
        "    if resume_from_checkpoint:\n",
        "        if checkpoint_path is None or not os.path.exists(checkpoint_path):\n",
        "            start_epoch = 0\n",
        "            print(\"No saved checkpoints to resume\")\n",
        "        else:\n",
        "            print(\"Checkpoint accessing...........\")\n",
        "            checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
        "            teacher_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            print(f\"Resuming training from epoch {start_epoch}\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        train_acc = train_model(teacher_model, train_loader, optimizer, lr_scheduler)\n",
        "        val_acc, val_logits = evaluate_model(val_loader, teacher_model)\n",
        "        print(f'Epoch {epoch + 1}: Train accuracy = {train_acc} Validation accuracy = {val_acc}')\n",
        "\n",
        "        if checkpoint_dir is not None:\n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': teacher_model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': lr_scheduler.state_dict()\n",
        "            }\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "    print(\"Evaluating on training data............\")\n",
        "    train_acc, train_logits = evaluate_model(train_loader, teacher_model)\n",
        "    print(\"Evaluating on validation data............\")\n",
        "    val_acc, val_logits = evaluate_model(val_loader, teacher_model)\n",
        "    print(\"Evaluating on testing data............\")\n",
        "    test_acc, test_logits = evaluate_model(test_loader, teacher_model)\n",
        "    print(f\"Test accuracy = {test_acc}\")\n",
        "    return train_logits, val_logits, test_logits"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "61d79989",
      "metadata": {},
      "source": [
        "Teacher model bert base uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "983ebf30",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer_base_uncased = transformers.BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "teacher_model_1 = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "\n",
        "train_loader_1, val_loader_1, test_loader_1, train_labels_1, val_labels_1, test_labels_1, train_subset, val_subset, test_subset = get_data(train_dataset, val_dataset, test_dataset, 1000, 220, 220, tokenizer_base_uncased)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ae0f86b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aryangupta/Library/Python/3.9/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint accessing...........\n",
            "Resuming training from epoch 5\n",
            "Evaluating on training data............\n",
            "Evaluating on validation data............\n",
            "Evaluating on testing data............\n",
            "Test accuracy = 0.55\n"
          ]
        }
      ],
      "source": [
        "train_logits_1, val_logits_1, test_logits_1 = fine_tune(teacher_model_1, train_loader_1, val_loader_1, test_loader_1, lr=5e-5, num_epochs=5, checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"teacher_model_1.pth\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "23d21a65",
      "metadata": {},
      "source": [
        "Teacher model bert large uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e8bc2418",
      "metadata": {},
      "outputs": [],
      "source": [
        "# tokenizer_large_uncased = transformers.BertTokenizerFast.from_pretrained('bert-large-uncased')\n",
        "# teacher_model_2 = transformers.BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=3)\n",
        "\n",
        "# train_loader_2, val_loader_2, test_loader_2, train_labels_2, val_labels_2, test_labels_2, train_subset, val_subset, test_subset = get_data(train_dataset, val_dataset, test_dataset, 500, 100, 100, tokenizer_large_uncased)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "aabf24f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_logits_2, val_logits_2, test_logits_2 = fine_tune(teacher_model_2, train_loader_2, val_loader_2, test_loader_2,lr=5e-5, checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"teacher_model_2.pth\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "520e81eb",
      "metadata": {
        "id": "520e81eb",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Step three: Student Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "717fa204",
      "metadata": {
        "id": "717fa204"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, l):\n",
        "        super(MLP, self).__init__()\n",
        "        bert_config = BertConfig(hidden_size=252, num_hidden_layers=2)\n",
        "        self.bert = BertModel(bert_config)\n",
        "        self.net1 = nn.Linear(252, 3)\n",
        "        # self.net4 = nn.Linear(60, 15)\n",
        "        # self.net5 = nn.Linear(15, 3)\n",
        "        self.leaky_relu = nn.LeakyReLU(l)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.bert(input_ids, attention_mask=attention_mask)[0]\n",
        "        output = torch.softmax(self.net1(bert_output[:, 0]), dim=1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "c4fb049c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(student_model, train_loader, optimizer, criterion, train_logits):\n",
        "    student_model.train()\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    i=0\n",
        "    for data in train_loader:\n",
        "        batch_size = len(data['input_ids'])\n",
        "        optimizer.zero_grad()\n",
        "        output = student_model(data['input_ids'], data['attention_mask'])\n",
        "        target = torch.tensor(train_logits[i*batch_size:(i+1)*batch_size, :], dtype=torch.float32)\n",
        "        loss = criterion(output, torch.softmax(target, dim=1, dtype = torch.float32))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        actual = target.argmax(dim=1, keepdim=True)\n",
        "        train_correct += pred.eq(actual.view_as(pred)).sum().item()\n",
        "        i +=1\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_acc = train_correct / len(train_loader.dataset)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def test(student_model, test_loader, criterion, test_logits):\n",
        "    student_model.eval()\n",
        "    test_loss = 0\n",
        "    test_correct = 0\n",
        "    pred_labels = []\n",
        "    pred_soft_labels = []\n",
        "    i=0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            batch_size = len(data['input_ids'])\n",
        "            output = student_model(data['input_ids'], data['attention_mask'])\n",
        "            target = torch.tensor(test_logits[i*batch_size:(i+1)*batch_size, :], dtype=torch.float32)\n",
        "            test_loss += criterion(output, torch.softmax(target, dim=1, dtype = torch.float32)).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            pred_labels.extend(pred.tolist())\n",
        "            pred_soft_labels.extend(output.max(dim=1)[0].tolist())\n",
        "            actual = target.argmax(dim=1, keepdim=True)\n",
        "            test_correct += pred.eq(actual.view_as(pred)).sum().item()\n",
        "            i += 1\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc = test_correct / len(test_loader.dataset)\n",
        "    \n",
        "    print(len(pred_labels), len(pred_labels[0]))\n",
        "    return test_loss, test_acc, np.array(pred_labels).reshape(-1,1), np.array(pred_soft_labels).reshape(-1,1)\n",
        "\n",
        "def train_student(student_model, train_logits, val_logits, test_logits, train_red_loader, val_red_loader, test_red_loader, student_optimizer=None, lr=1e-4, epoch=50, checkpoint_dir=None, resume_from_checkpoint=True, checkpoint_file=None):\n",
        "    if(student_optimizer is None): student_optimizer = torch.optim.Adam(student_model.parameters(), lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # epoch = 30\n",
        "    print(\"Training...........\")\n",
        "    checkpoint_path = checkpoint_dir + checkpoint_file\n",
        "\n",
        "    if resume_from_checkpoint:\n",
        "        if checkpoint_path is None or not os.path.exists(checkpoint_path):\n",
        "            start_epoch = 0\n",
        "            print(\"No saved checkpoints to resume\")\n",
        "        else:\n",
        "            print(\"Checkpoint accessing...........\")\n",
        "            checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
        "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            student_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            print(f\"Resuming training from epoch {start_epoch}\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "    for i in range(start_epoch, epoch):\n",
        "        train_loss, train_acc = train(student_model, train_red_loader, student_optimizer, criterion, train_logits)\n",
        "        if(i%10 == 0):   print(f\"Epoch {i}   Train loss: {train_loss}    Train accuracy: {train_acc}\")\n",
        "        # print(train_loss, train_acc)\n",
        "        if checkpoint_dir is not None:\n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': student_model.state_dict(),\n",
        "                'optimizer_state_dict': student_optimizer.state_dict()\n",
        "            }\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "    \n",
        "    print(\"Evaluating on training data..................\")\n",
        "    train_loss, train_acc, train_pred_labels, train_pred_soft_labels = test(student_model, train_red_loader, criterion, train_logits)\n",
        "    print(f\"Training loss: {train_loss} Train accuracy:  {train_acc}\")\n",
        "    \n",
        "    print(\"Evaluating on validation data..................\")\n",
        "    val_loss, val_acc, val_pred_labels, val_pred_soft_labels = test(student_model, val_red_loader, criterion, val_logits)\n",
        "    print(f\"Validation loss: {val_loss} Validation accuracy:  {val_acc}\")\n",
        "\n",
        "    print(\"Evaluating on testing data..................\")\n",
        "    test_loss, test_acc, test_pred_labels, test_pred_soft_labels  = test(student_model, test_red_loader, criterion, test_logits)\n",
        "    print(f\"Testing loss: {test_loss} Test accuracy:  {test_acc}\")\n",
        "    \n",
        "    # print(test_pred_labels.shape)\n",
        "    return train_pred_labels, val_pred_labels, test_pred_labels, train_pred_soft_labels, val_pred_soft_labels, test_pred_soft_labels\n",
        "\n",
        "def ensemble_models(train_pred_lists, val_pred_lists, test_pred_lists):\n",
        "    \n",
        "    train_pred = np.array([np.argmax(np.bincount(np.array(train_pred_lists)[:,i])) for i in range(len(train_pred_lists[1]))])\n",
        "    val_pred = np.array([np.argmax(np.bincount(np.array(val_pred_lists)[:,i])) for i in range(len(val_pred_lists[1]))])\n",
        "    test_pred = np.array([np.argmax(np.bincount(np.array(test_pred_lists)[:,i])) for i in range(len(test_pred_lists[1]))])\n",
        "    \n",
        "    return train_pred, val_pred, test_pred\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e2ca7fe1",
      "metadata": {},
      "source": [
        "Student model: - Adam optimizer - teacher_model_1\n",
        "\n",
        "student_adam_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d68ff0bc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...........\n",
            "Checkpoint accessing...........\n",
            "Resuming training from epoch 51\n",
            "Evaluating on training data..................\n",
            "1000 1\n",
            "Training loss: 0.06988550788164138 Train accuracy:  0.418\n",
            "Evaluating on validation data..................\n",
            "220 1\n",
            "Validation loss: 0.07294037016955289 Validation accuracy:  0.35909090909090907\n",
            "Evaluating on testing data..................\n",
            "220 1\n",
            "Testing loss: 0.06973586949435147 Test accuracy:  0.44545454545454544\n"
          ]
        }
      ],
      "source": [
        "student_adam_1 = MLP(0.1)\n",
        "student_adam_1_optim = torch.optim.Adam(student_adam_1.parameters(), lr=1e-4)\n",
        "train_pred_labels_student_adam_1, val_pred_labels_student_adam_1, test_pred_labels_student_adam_1, train_pred_soft_labels_student_adam_1, val_pred_soft_labels_student_adam_1, test_pred_soft_labels_student_adam_1 = train_student(student_adam_1, train_logits_1, val_logits_1, test_logits_1,train_loader_1, val_loader_1, test_loader_1, student_optimizer=student_adam_1_optim, lr=1e-4, epoch=50,  checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"student_adam_1.pth\" )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "29fadc02",
      "metadata": {},
      "source": [
        "Student model: - SGD optimizer - teacher_model_1\n",
        "\n",
        "student_sgd_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "83e46477",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...........\n",
            "Checkpoint accessing...........\n",
            "Resuming training from epoch 51\n",
            "Evaluating on training data..................\n",
            "1000 1\n",
            "Training loss: 0.06988550788164138 Train accuracy:  0.418\n",
            "Evaluating on validation data..................\n",
            "220 1\n",
            "Validation loss: 0.07294037016955289 Validation accuracy:  0.35909090909090907\n",
            "Evaluating on testing data..................\n",
            "220 1\n",
            "Testing loss: 0.06973586949435147 Test accuracy:  0.44545454545454544\n"
          ]
        }
      ],
      "source": [
        "student_sgd_1 = MLP(0.1)\n",
        "student_sgd_1_optim = torch.optim.SGD(student_sgd_1.parameters(), lr=1e-4, momentum=0.9)\n",
        "train_pred_labels_student_sgd_1, val_pred_labels_student_sgd_1, test_pred_labels_student_sgd_1, train_pred_soft_labels_student_sgd_1, val_pred_soft_labels_student_sgd_1, test_pred_soft_labels_student_sgd_1 = train_student(student_sgd_1, train_logits_1, val_logits_1, test_logits_1,train_loader_1, val_loader_1, test_loader_1, student_optimizer=student_sgd_1_optim, lr=1e-4, epoch=50,  checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"student_sgd_1.pth\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75ec082e",
      "metadata": {},
      "source": [
        "Using Adam optimiser"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f5f0f6b8",
      "metadata": {
        "id": "f5f0f6b8",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Step four: Experimenting by increasing number of layers in student model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe250714",
      "metadata": {},
      "source": [
        "For 2 layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "cbdb2e27",
      "metadata": {
        "id": "cbdb2e27"
      },
      "outputs": [],
      "source": [
        "class MLP_2(nn.Module):\n",
        "    def __init__(self, l):\n",
        "        super(MLP_2, self).__init__()\n",
        "        bert_config = BertConfig(hidden_size=252, num_hidden_layers=2)\n",
        "        self.bert = BertModel(bert_config)\n",
        "        self.net1 = nn.Linear(252, 100)\n",
        "        self.net4 = nn.Linear(100, 3)\n",
        "        self.leaky_relu = nn.LeakyReLU(l)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
        "        output = self.net1(bert_output[:, 0, :])\n",
        "        output = self.leaky_relu(output)\n",
        "        output = self.net4(output)\n",
        "        output = torch.softmax(output, dim=1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d271c53b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...........\n",
            "Checkpoint accessing...........\n",
            "Resuming training from epoch 21\n",
            "Evaluating on training data..................\n",
            "1000 1\n",
            "Training loss: 0.07218236720561981 Train accuracy:  0.402\n",
            "Evaluating on validation data..................\n",
            "220 1\n",
            "Validation loss: 0.07623248154466802 Validation accuracy:  0.3409090909090909\n",
            "Evaluating on testing data..................\n",
            "220 1\n",
            "Testing loss: 0.07265133424238725 Test accuracy:  0.4090909090909091\n"
          ]
        }
      ],
      "source": [
        "student_adam_2 = MLP_2(0.1)\n",
        "student_adam_2_optim = torch.optim.Adam(student_adam_2.parameters(), lr=1e-4)\n",
        "train_pred_labels_student_adam_2, val_pred_labels_student_adam_2, test_pred_labels_student_adam_2, train_pred_soft_labels_student_adam_2, val_pred_soft_labels_student_adam_2, test_pred_soft_labels_student_adam_2 = train_student(student_adam_2, train_logits_1, val_logits_1, test_logits_1,train_loader_1, val_loader_1, test_loader_1, student_optimizer=student_adam_2_optim, lr=1e-4, epoch=20, checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"student_adam_2.pth\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24b10921",
      "metadata": {},
      "source": [
        "For 3 layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d0ebe22b",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP_3(nn.Module):\n",
        "    def __init__(self, l):\n",
        "        super(MLP_3, self).__init__()\n",
        "        bert_config = BertConfig(hidden_size=252, num_hidden_layers=2)\n",
        "        self.bert = BertModel(bert_config)\n",
        "        self.net1 = nn.Linear(252, 60)\n",
        "        self.net4 = nn.Linear(60, 15)\n",
        "        self.net5 = nn.Linear(15, 3)\n",
        "        self.leaky_relu = nn.LeakyReLU(l)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.bert(input_ids, attention_mask=attention_mask)[0]\n",
        "        output = self.leaky_relu(self.net1(bert_output[:, 0, :]))\n",
        "        output = self.leaky_relu(self.net4(output))\n",
        "        output = torch.softmax(self.net5(output), dim=1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6899cfd5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...........\n",
            "Checkpoint accessing...........\n",
            "Resuming training from epoch 21\n",
            "Evaluating on training data..................\n",
            "1000 1\n",
            "Training loss: 0.0728652669787407 Train accuracy:  0.38\n",
            "Evaluating on validation data..................\n",
            "220 1\n",
            "Validation loss: 0.0769100774418224 Validation accuracy:  0.3\n",
            "Evaluating on testing data..................\n",
            "220 1\n",
            "Testing loss: 0.07193247161128304 Test accuracy:  0.41363636363636364\n"
          ]
        }
      ],
      "source": [
        "student_adam_3 = MLP_3(0.1)\n",
        "student_adam_3_optim = torch.optim.Adam(student_adam_3.parameters(), lr=1e-4)\n",
        "train_pred_labels_student_adam_3, val_pred_labels_student_adam_3, test_pred_labels_student_adam_3, train_pred_soft_labels_student_adam_3, val_pred_soft_labels_student_adam_3, test_pred_soft_labels_student_adam_3 = train_student(student_adam_3, train_logits_1, val_logits_1, test_logits_1,train_loader_1, val_loader_1, test_loader_1, student_optimizer=student_adam_3_optim, lr=1e-4, epoch=20, checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"student_adam_3.pth\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09ffca0",
      "metadata": {
        "id": "d09ffca0",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Step five: Creating multiple 1-o-1 teacher student\n",
        "\n",
        "Teacher models have learning rates 2e-5, 3e-5, 5e-5 as given in paper"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f184e6",
      "metadata": {},
      "source": [
        "Learning rate = 2e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c970627a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint accessing...........\n",
            "Resuming training from epoch 5\n",
            "Evaluating on training data............\n",
            "Evaluating on validation data............\n",
            "Evaluating on testing data............\n",
            "Test accuracy = 0.5545454545454546\n"
          ]
        }
      ],
      "source": [
        "teacher_model_11 = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "train_loader_11, val_loader_11, test_loader_11, train_labels_11, val_labels_11, test_labels_11, train_subset, val_subset, test_subset = get_data(train_dataset, val_dataset, test_dataset, 1000, 220, 220, tokenizer_base_uncased)\n",
        "train_logits_11, val_logits_11, test_logits_11 = fine_tune(teacher_model_11, train_loader_11, val_loader_11, test_loader_11, lr=2e-5, num_epochs=5, checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"teacher_model_11.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "db55f0de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...........\n",
            "Checkpoint accessing...........\n",
            "Resuming training from epoch 21\n",
            "Evaluating on training data..................\n",
            "1000 1\n",
            "Training loss: 0.06833493030071258 Train accuracy:  0.432\n",
            "Evaluating on validation data..................\n",
            "220 1\n",
            "Validation loss: 0.07114373608068987 Validation accuracy:  0.34545454545454546\n",
            "Evaluating on testing data..................\n",
            "220 1\n",
            "Testing loss: 0.06951195380904458 Test accuracy:  0.39545454545454545\n"
          ]
        }
      ],
      "source": [
        "student_11 = MLP(0.1)\n",
        "student_11_optim = torch.optim.Adam(student_11.parameters(), lr=1e-4)\n",
        "train_pred_labels_student_11, val_pred_labels_student_11, test_pred_labels_student_11, train_pred_soft_labels_student_11, val_pred_soft_labels_student_11, test_pred_soft_labels_student_11 = train_student(student_11, train_logits_11, val_logits_11, test_logits_11,train_loader_11, val_loader_11, test_loader_11, student_optimizer=student_11_optim, lr=1e-4, epoch=20, checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"student_11.pth\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "164deac7",
      "metadata": {},
      "source": [
        "Learning Rate = 3e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "34e20865",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint accessing...........\n",
            "Resuming training from epoch 5\n",
            "Evaluating on training data............\n",
            "Evaluating on validation data............\n",
            "Evaluating on testing data............\n",
            "Test accuracy = 0.5590909090909091\n"
          ]
        }
      ],
      "source": [
        "teacher_model_12 = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "train_loader_12, val_loader_12, test_loader_12, train_labels_12, val_labels_12, test_labels_12, train_subset, val_subset, test_subset = get_data(train_dataset, val_dataset, test_dataset, 1000, 220, 220, tokenizer_base_uncased)\n",
        "train_logits_12, val_logits_12, test_logits_12 = fine_tune(teacher_model_12, train_loader_12, val_loader_12, test_loader_12, lr=3e-5, num_epochs=5, checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"teacher_model_12.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ff5adbc4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...........\n",
            "Checkpoint accessing...........\n",
            "Resuming training from epoch 21\n",
            "Evaluating on training data..................\n",
            "1000 1\n",
            "Training loss: 0.06961423182487488 Train accuracy:  0.384\n",
            "Evaluating on validation data..................\n",
            "220 1\n",
            "Validation loss: 0.07084848040884191 Validation accuracy:  0.38636363636363635\n",
            "Evaluating on testing data..................\n",
            "220 1\n",
            "Testing loss: 0.0704539878801866 Test accuracy:  0.39090909090909093\n"
          ]
        }
      ],
      "source": [
        "student_12 = MLP(0.1)\n",
        "student_12_optim = torch.optim.Adam(student_12.parameters(), lr=1e-4)\n",
        "train_pred_labels_student_12, val_pred_labels_student_12, test_pred_labels_student_12, train_pred_soft_labels_student_12, val_pred_soft_labels_student_12, test_pred_soft_labels_student_12 = train_student(student_12, train_logits_12, val_logits_12, test_logits_12,train_loader_12, val_loader_12, test_loader_12, student_optimizer=student_12_optim, lr=1e-4, epoch=20, checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"student_12.pth\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6276fade",
      "metadata": {},
      "source": [
        "Learning Rate = 5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "77fc841a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint accessing...........\n",
            "Resuming training from epoch 5\n",
            "Evaluating on training data............\n",
            "Evaluating on validation data............\n",
            "Evaluating on testing data............\n",
            "Test accuracy = 0.6272727272727273\n"
          ]
        }
      ],
      "source": [
        "teacher_model_13 = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "train_loader_13, val_loader_13, test_loader_13, train_labels_13, val_labels_13, test_labels_13, train_subset, val_subset, test_subset = get_data(train_dataset, val_dataset, test_dataset, 1000, 220, 220, tokenizer_base_uncased)\n",
        "train_logits_13, val_logits_13, test_logits_13 = fine_tune(teacher_model_13, train_loader_13, val_loader_13, test_loader_13, lr=5e-5, num_epochs=5, checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"teacher_model_13.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "0fd60a68",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...........\n",
            "Checkpoint accessing...........\n",
            "Resuming training from epoch 21\n",
            "Evaluating on training data..................\n",
            "1000 1\n",
            "Training loss: 0.07187032806873321 Train accuracy:  0.36\n",
            "Evaluating on validation data..................\n",
            "220 1\n",
            "Validation loss: 0.07212309295480901 Validation accuracy:  0.38181818181818183\n",
            "Evaluating on testing data..................\n",
            "220 1\n",
            "Testing loss: 0.0721461529081518 Test accuracy:  0.37727272727272726\n"
          ]
        }
      ],
      "source": [
        "student_13 = MLP(0.1)\n",
        "student_13_optim = torch.optim.Adam(student_13.parameters(), lr=1e-4)\n",
        "train_pred_labels_student_13, val_pred_labels_student_13, test_pred_labels_student_13, train_pred_soft_labels_student_13, val_pred_soft_labels_student_13, test_pred_soft_labels_student_13 = train_student(student_13, train_logits_13, val_logits_13, test_logits_13,train_loader_13, val_loader_13, test_loader_13, student_optimizer=student_13_optim, lr=1e-4, epoch=20, checkpoint_dir=\"./checkpoints/\", checkpoint_file=\"student_13.pth\" )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "91631d83",
      "metadata": {
        "id": "91631d83",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Step six: Performing majority voting ensemble on student models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "bb3cb5bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "train_pred_lists = []\n",
        "train_pred_lists.append(list(itertools.chain.from_iterable(train_pred_labels_student_11)))\n",
        "train_pred_lists.append(list(itertools.chain.from_iterable(train_pred_labels_student_12)))\n",
        "train_pred_lists.append(list(itertools.chain.from_iterable(train_pred_labels_student_13)))\n",
        "\n",
        "val_pred_lists = []\n",
        "val_pred_lists.append(list(itertools.chain.from_iterable(val_pred_labels_student_11)))\n",
        "val_pred_lists.append(list(itertools.chain.from_iterable(val_pred_labels_student_12)))\n",
        "val_pred_lists.append(list(itertools.chain.from_iterable(val_pred_labels_student_13)))\n",
        "\n",
        "test_pred_lists = []\n",
        "test_pred_lists.append(list(itertools.chain.from_iterable(test_pred_labels_student_11)))\n",
        "test_pred_lists.append(list(itertools.chain.from_iterable(test_pred_labels_student_12)))\n",
        "test_pred_lists.append(list(itertools.chain.from_iterable(test_pred_labels_student_13)))\n",
        "\n",
        "train_pred, val_pred, test_pred = ensemble_models(train_pred_lists, val_pred_lists, test_pred_lists)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "b73fdbc8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy:  0.354\n",
            "Validation accuracy:  0.33181818181818185\n",
            "Test accuracy:  0.36818181818181817\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "train_acc = accuracy_score(train_labels_1, train_pred)\n",
        "val_acc = accuracy_score(val_labels_1, val_pred)\n",
        "test_acc = accuracy_score(test_labels_1, test_pred)\n",
        "\n",
        "print(f\"Train accuracy:  {train_acc}\")\n",
        "print(f\"Validation accuracy:  {val_acc}\")\n",
        "print(f\"Test accuracy:  {test_acc}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09c05f7bade7400fbd19f3d3f7b8c1c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1840b7a0c6714b0cad6881c73c691272": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "233e512792604abb804b8ce2fc8d5d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b48385d05aa040728f3ab000bc126065",
            "placeholder": "",
            "style": "IPY_MODEL_78b3c9719d4e4fe892bb599007eae2e5",
            "value": " 9912422/9912422 [00:00&lt;00:00, 14589880.14it/s]"
          }
        },
        "259c52ab16b041aab75332c3d5e27c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a71ca68e12a64c8ba7711f1d253ef787",
            "placeholder": "",
            "style": "IPY_MODEL_98a7b698b4ab4822b403ba313d39c004",
            "value": " 4542/4542 [00:00&lt;00:00, 104197.48it/s]"
          }
        },
        "3053808b5ab64b49b38b2abdece6aea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de8494e6a5924e27a6a2dc2dfdc9f006",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7460564b7394b2a99f9a0d86cdb8695",
            "value": 4542
          }
        },
        "33da380cdd6a42f080ae2b71af368d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ce1ce06f4ee4f7f8c81474708e5a841",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad6e210ecf3344cc8ed912a4d6034f38",
            "value": 1648877
          }
        },
        "49b35ab57e6744b880df633392a5939b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2f9e49e5107465283e2b7461a853e31",
            "placeholder": "",
            "style": "IPY_MODEL_6c5ec9845b664d9bb333a95ab07b4deb",
            "value": "100%"
          }
        },
        "521121357c454c11bdf926712e588af2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a07523a7ac44a1be20e11c2e8c51f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1840b7a0c6714b0cad6881c73c691272",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b56478ee5b3443cfb373829f1fd3b48e",
            "value": 28881
          }
        },
        "68b25eb6f5a74208800dc9f50d21c39d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c5ec9845b664d9bb333a95ab07b4deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73583fffc0ee4c0fac0e37c9975650f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78b3c9719d4e4fe892bb599007eae2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c74230b6af94777ac1b9a0bc40b8955": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73583fffc0ee4c0fac0e37c9975650f4",
            "placeholder": "",
            "style": "IPY_MODEL_fcf734572bae4317a5dd6fe6fb8e1243",
            "value": " 1648877/1648877 [00:00&lt;00:00, 239233.13it/s]"
          }
        },
        "7ce1ce06f4ee4f7f8c81474708e5a841": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e8976fd569f4085b5321ccc76d0cafa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a852c77e1c439f96e2f82984b14116": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a82ade129f064dfa8784e0ed1d8913fd",
            "placeholder": "",
            "style": "IPY_MODEL_09c05f7bade7400fbd19f3d3f7b8c1c0",
            "value": "100%"
          }
        },
        "90d54512218b4267be892d365abbc82d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a7b698b4ab4822b403ba313d39c004": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bff02afd04c4362b0870ab4e0687405": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9963b02a92848e7bfd360443fd79b1e",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0d7f8cf2cfa41cc8c4ada7c28988afd",
            "value": 9912422
          }
        },
        "a0b91b5ed3414a888014fe1fb9434d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d54512218b4267be892d365abbc82d",
            "placeholder": "",
            "style": "IPY_MODEL_f64132cad98140f88c2a1fc203da0b48",
            "value": " 28881/28881 [00:00&lt;00:00, 462710.25it/s]"
          }
        },
        "a0bbc5b9e5124be1bebcbcec2b283ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521121357c454c11bdf926712e588af2",
            "placeholder": "",
            "style": "IPY_MODEL_c11fd204d8b9486a83644cb31fdea9fe",
            "value": "100%"
          }
        },
        "a1b46c6478cb4b9ab0daca9e9b789974": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68b25eb6f5a74208800dc9f50d21c39d",
            "placeholder": "",
            "style": "IPY_MODEL_fa4fc55110884cebae18022bb8ffa936",
            "value": "100%"
          }
        },
        "a71ca68e12a64c8ba7711f1d253ef787": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a82ade129f064dfa8784e0ed1d8913fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6e210ecf3344cc8ed912a4d6034f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0d7f8cf2cfa41cc8c4ada7c28988afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b48385d05aa040728f3ab000bc126065": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56478ee5b3443cfb373829f1fd3b48e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7460564b7394b2a99f9a0d86cdb8695": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9d52f0912ab4fdabb718d1f518e3d03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c11fd204d8b9486a83644cb31fdea9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5096f06134d49d49799b58ab0b504ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0bbc5b9e5124be1bebcbcec2b283ae1",
              "IPY_MODEL_9bff02afd04c4362b0870ab4e0687405",
              "IPY_MODEL_233e512792604abb804b8ce2fc8d5d44"
            ],
            "layout": "IPY_MODEL_b9d52f0912ab4fdabb718d1f518e3d03"
          }
        },
        "de8494e6a5924e27a6a2dc2dfdc9f006": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfdc799c81a54f2abe498190658ef99b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49b35ab57e6744b880df633392a5939b",
              "IPY_MODEL_65a07523a7ac44a1be20e11c2e8c51f8",
              "IPY_MODEL_a0b91b5ed3414a888014fe1fb9434d85"
            ],
            "layout": "IPY_MODEL_ffbbf295961e4b509e7cac4fb685f3a7"
          }
        },
        "e544ba30075b4abd8181e0e4c87df4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90a852c77e1c439f96e2f82984b14116",
              "IPY_MODEL_3053808b5ab64b49b38b2abdece6aea2",
              "IPY_MODEL_259c52ab16b041aab75332c3d5e27c64"
            ],
            "layout": "IPY_MODEL_7e8976fd569f4085b5321ccc76d0cafa"
          }
        },
        "e9963b02a92848e7bfd360443fd79b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2f9e49e5107465283e2b7461a853e31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64132cad98140f88c2a1fc203da0b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6f5999fd9584550bdb3ff9bae56dde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1b46c6478cb4b9ab0daca9e9b789974",
              "IPY_MODEL_33da380cdd6a42f080ae2b71af368d9e",
              "IPY_MODEL_7c74230b6af94777ac1b9a0bc40b8955"
            ],
            "layout": "IPY_MODEL_fe582772dace4a42b31b4a413b905bf1"
          }
        },
        "fa4fc55110884cebae18022bb8ffa936": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcf734572bae4317a5dd6fe6fb8e1243": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe582772dace4a42b31b4a413b905bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffbbf295961e4b509e7cac4fb685f3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
